job_id,timestamp,custom_mode,custom_submode,custom_scaling,shared_dim,shared_uv,dynamic_uv,custom_d_init,custom_sqrt_a,custom_disable_identity,init_type,d_init_type,lora_r,lora_c,lora_alpha,target_modules,task,dataset,dataset_format,train_samples,metric_samples,eval_samples,epochs,train_bs,metric_bs,eval_bs,eval_steps,logging_steps,metrics_enabled,seed,model,quantize,lr,wd,accumulation_steps,generate_samples,warmup_ratio,lr_scheduler_type,output_dir
0,20250804_173818,sara,none,0,11008,1,1,1.0,5,True,1,100,256,1,1,no_head,math,gsm10k,alpaca-clean,8000,100,64,1,4,10,4,20,1,0,42,meta-llama/Llama-2-7b-hf,True,0.004,0.0,4,True,0.1,cosine,training_output
0,20250804_174148,sara,none,0,11008,1,1,1.0,5,True,1,100,256,1,1,no_head,math,gsm10k,alpaca-clean,8000,100,64,1,4,10,4,20,1,0,42,meta-llama/Llama-2-7b-hf,True,0.004,0.0,4,True,0.1,cosine,training_output
0,20250804_174433,sara,none,0,11008,1,1,1.0,5,True,1,100,256,1,1,no_head,math,gsm10k,alpaca-clean,8000,100,64,1,4,10,4,20,1,0,42,meta-llama/Llama-2-7b-hf,True,0.004,0.0,4,True,0.1,cosine,training_output
0,20250804_174552,sara,none,0,11008,1,1,1.0,5,True,1,100,256,1,1,no_head,math,gsm10k,alpaca-clean,8000,100,64,1,4,10,4,20,1,0,42,meta-llama/Llama-2-7b-hf,True,0.004,0.0,4,True,0.1,cosine,training_output
